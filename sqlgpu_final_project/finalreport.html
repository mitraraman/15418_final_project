<html>
<head>
<title>CMU 15-418/618 (Spring 2013) Final Project</title>

<link rel="stylesheet" type="text/css" href="css/style.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.6/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.6.1.min.js"><\/script>')</script>

    <script src="js/jquery.smoothscroll.js"></script>
    <script src="js/jquery.nivo.slider.pack.js"></script>
    <script src="js/jquery.easing-1.3.pack.js"></script>
    <script src="js/jquery.fancybox-1.3.4.pack.js"></script>

</head>
<body>

<div id="header-wrap">
	<header>
		<div id="title">
			<h1>SQL on GPU with Efficient <br />Relational Algebra Algorithms</h1>
			
		</div>

	        <div id="myNavigation" class="pageScrollerNav">
            <ul>
                <li><a href="#">Summary</a></li>
                <li><a href="#">Background</a></li>
                <li><a href="#">Approach</a></li>
                <li><a href="#">Execution</a></li>
                <li><a href="#">Results</a></li>
                <li><a href="#">References</a></li>
            </ul>
        </div>
	</header>
</div>

<div id="wrapper">
<div class="section" id="summary">
<br /><br /><br /><br /><h2>Summary</h2>
<p>We want to analyze the performance of implementing database operations on a GPU versus a CPU. We have chosen to implement the relational algebra operations SELECT and JOIN on a GPU to simulate the relational database queries in order to investigate the viability of accelerating a database on GPU. To fairly analyze the performances on GPU and CPU, we have implemented fairly optimized corresponding operations by using SIMD, and we have implemented sequential versions of the operations on the multi-core CPU machines to validate the results as well.</p>
</div>

<div class="section" id="background">
<br /><br /><br /><br />	
<h2>Background</h2>
<h3>SQL as Relational Algebra</h3>
<p>Relational algebra is a procedural query language, which consists of a set of operations that take one or two relations as input and produce a new relation as their result. The fundamental operations in relational algebra are: select, project, union, and set difference. SQL is a superset of relational algebra, so it is relationally complete which means that the language can perform all basic and meaningful operations on relations through relational algebra. Operators in relational algebra are not necessarily the same as SQL operators, even if they have the same name. For example, the SELECT statement exists in SQL, and also exists in relational algebra. These two uses of SELECT are not the same. The DBMS must take whatever SQL statements the user types in and translate them into relational algebra operations before applying them to the database. SQL statements are given to parsers that convert the queries into equivalent relational algebra expressions. For instance, this SQL query<br /><br />
<img src="images/sqlquery.png" /><br /><br />
is equivalent to the following relational algebra expression<br /><br />
<img src="images/relalg.png" /> <br /> <br />
</p>
<h3>SELECT and JOIN on a GPU and a CPU</h3>
<p>To implement SELECT and JOIN, we referred to several papers that have been written about translating SQL queries into relational algebra. We wanted to efficiently use the computation power and memory space of the GPU and CPU, respectively, so we enhacned the algorithms of each of the operations. Each operation is run on several threads on the GPU, so the algorithms require quick division and merging of the tables. On the CPU, we wanted to execute the queries sequentially and with some parallelism through various techniques we have learned throughout the course such as OpenMP and SIMD parallelism. We initially considered memory transfer of the data between the CPU and GPU as part of our implementations, which would require some usage of MemSQL to efficiently store the tables in memory. However, more research showed that memory transfer times can vary based on the machine that is in use, so we chose to eliminate this part of in our implementations of the queries.</p>

<h3>HW + SW Information</h3>
<p>
	We are executing the relational algebra operations on a GDX 480s GPU and on a quad-core CPU. These machines were readily available to us through the CMU computers, and we found it best to use them for testing purposes. Although there are other machines that will give better performance and are more optimal, we chose not to switch over machines in the middle of our project. The programs are written in CUDA on the GPU and in C++ on the CPU.
</p>
<br />

</div>

<div class="section" id="approach">
<br /><br /><br /><br />
<h2>Algorithm & Approach</h2>

<h3>General Approach</h3>
No matter which operation is implemented in GPU, the general algorithm is similar, and there are three stages:
<ul>
<li>stage 1: Partition tuples into blocks of threads</li>
<li>stage 2: Mapping tuples based on predicate and generate histogram cross blocks</li>
<li>stage 3: Gather resulting tuples into condensed buffer based on histogram</li>
</ul>
The actual implementations are around these 3 stages, but vary on the number of cuda kernels to achieve the goal of each stage. eg. JOIN needs three kernels to make histogram ready while SELECT only needs one. There are more implementation details in the optimization section.
<br /><br />
<h3>SELECT Operation</h3> The GPU takes in the input table and divides the tuples among the available worker threads. Each thread then performs the "select" operation on each tuple and reports whether the tuple is a match for the query by storing a 1 in a match_index_array at the appropriate index. The GPU then counts the qualifying tuples under each thread and reports the "result size" for each thread. Next, the GPU performs a prefix sum of the result sizes and creates a histogram from which it maps the qualifying tuples to the output buffer. In addition to executing one query at a time on the GPU, we added an additional implementation of SELECT which supported streams of queries. Our hope was that this would help hide the overhead of computation and the bottleneck that arises from the GPU-startup and disk accesses. Below is an image depicting the SELECT algorithm from the GPU as taken from the academic paper, <a href="">"Efficient Relational Algebra Algorithms and Data Structures for GPU"</a>.<br /><br />
<img src="images/select_algo.png" /><br />
On the CPU, we implemeneted a simple serial version as well as a parallel version that uses SIMD instructions to improve performance. We felt that it was fair to compare a parallelized implementation on the CPU to a parallelized implementation on the GPU to accurately measure better performance of the operations. The CPU version uses all four cores on the machine by placing pertinent blocks of code in parallel for loops. Each thread checks tuples from the table to see if they are qualifying, and then follows a similar algorithm as in the GPU by performing a prefix sum on the matching indeces of the tuples. This allows for maximum parallelism on the CPU using SIMD.
<br /><br />
<h3>JOIN Operation</h3> 
The JOIN operation is the most complicated algorithm, it is further complicated by the merge stage of the algorithm, which involves identifying subsets of the partitioned relations with overlapping attributes and performing the cross product for each subset. This presents a significant problem to parallel implementations of the algorithm that eventually write to a statically allocated, dense array. 

We assign threads from the GPU to similar sized blocks from one table and perform a binary search algorithm on the second table to find tuples within the bounds of the block. Once the number of matching tuples is computed, we once again perform a prefix sum operation to find an upper bound for the total number of qualifying tuples from the query. We then merge each tuple with its respective matching tuples and perform another prefix sum on the actual number of qualifying tuples to create a histogram of the final result. Each thread then merges their final results into the final output buffer.<br /><br />
<img src="images/join_algo.png" />
<br /><br />
The JOIN operation is quite similar on the CPU as on the GPU, we have tried two matching approaches for the first step: binary search and brute force. In brute force, each tuple from the outer relation goes through the entire inner relation, which gives O(M) for every search, where M is the size of the inner relation. In binary search, it is O(logM).
Since we utilize the fact that the relation is already sorted, binary seatch outperforms the brute force.
<br /><br />

<br />

</div>

<div class="section" id="execution">
<br /><br /><br /><br />
<h2>Execution & Optimization</h2>
<h3>SELECT on GPU</h3>
<h4>General CUDA Implementation</h4><br /><br />
<h4>CUDA Kernels</h4><br /><br />
<h4>Using Streams</h4>
<img src="images/stream.png" /><br />
The main overhead is from transferring data, but not that much. we try to explore the potential of hiding the latency by setting up cuda stream. We set up three cuda streams, while stream 0 is doing the computation, stream 1 is transferring data from host to device, stream 2 is transferring data from device to host. So the data transfer bottleneck would be somehow hidden by pipelining.However, the actual execution time of computation is not the same as the time of transferring data, the latency is not completely hidden.<br /><br />

<h3>SELECT on CPU</h3>
<h4>Single Threaded Implementation</h4><br /><br />
<h4>SIMD Implementation</h4><br /><br />

<h3>JOIN on GPU</h3>
<h4>General CUDA Implementaiton</h4><br /><br />
We assume we are working on sorted tuples, the paper is using binary search for each block to find out lower bound and upper bound, which is really inefficient in GPU. We implement p-nary search based on the paper and tweak it for our case. The original p-nary algorithm tries to use all of threads cross blocks to find out the matching, and in our case, we only use all of threads inside one block to find out the boundaries for this block. Besides, p-nary outputs the items that match, but if there is duplication in the buffer, there is no guaranteed which one p-nary search will output. So, we makes two versions of p-nary search, one for searching for lower_bound, where we only keep result that has lower index and one for upper_bound, where we only keeps result that has larger index. The reason we do this is to make sure the correctness of join that no tuple is left.
<h4>CUDA Kernels</h4><br />
<br />

<h3>JOIN on CPU</h3>
<h4>Single Threaded Implementation</h4><br /><br />

<h3>Optimizations</h3>
<h4>Memory Transfer</h4><br />
<h4>OpenMP Attempt</h4><br />
<h4>Streams</h4><br />
<h4>P-nary Search vs Brute Force</h4>

<h3>Implementation Issues</h3>
<p>
There were several issues to consider when implementing these operations. First, the GPU algorithms are theoretically simple but we ran into coherence and atomicity issues when implementing them. The threads needed to update their values in the output buffers in a sorted order to display the qualifying tuples of the query correctly. Second, when implementing parallelism on the CPU, we attempted to use OpenMP since it provided several instructions to help execute parallelism across the tuples for each query. However, we discovered that it wasn't as simple as making the "for" loop in the sequential version a "parallel for" -- we ran into atomicity issues similar as in the GPU version. So, when attempting to execute a similar algorithm on the CPU as on the GPU, we discovered that the speedup actually decreased and was worse than the simple sequential version. 
</p>
<br />
</div>

<div class="section" id="results">
<br /><br /><br /><br />
<h2>Results & Analysis - MITRA & YINGCHAO</h2>
<h3>SELECT: Speedup vs. Table Size</h3>
<p>Here are the results from SELECT operation executed on CPU and GPU. We executed SELECT on the GPU with CUDA, on the GPU using CUDA kernels, on the GPU using streams, on the CPU using a single thread, and on the CPU implementing SIMD and tasks. We display the speed for the queries on different query sizes.<br />
<h4>All Results: (y-axis: number of tuples in the relation, we scale by 3 to show the effect from STREAM, x-aix: execution time(ms))</h4><br />
<img src="images/select_all.png" />
<br /><br />
<h4>GPU with CUDA plus data transfer: (y-axis: execution time(ms), x-axis: number of tuples)</h4>
<br />
<img src="images/select_gpu.png" />
<br /><br />
<h4>GPU with CUDA Kernels:  (y-axis: execution time(ms), x-axis: number of tuples)</h4>
<br />
<img src="images/select_cuda_kernel.png" />
<br /><br />
<h4>GPU with Streams:  (y-axis: execution time(ms), x-axis: number of tuples)</h4>
<br />
<img src="images/select_streams.png" />
<br /><br />
<h4>CPU with Single Thread:  (y-axis: execution time(ms), x-axis: number of tuples)</h4>
<br />
<img src="images/select_cpu.png" />
<br /><br />
<h4>CPU with SIMD and Tasks:  (y-axis: execution time(ms), x-axis: number of tuples)</h4>
<br />
<img src="images/select_simd_tasks.png" />
</p>
<h3>JOIN: Speedup vs. Table Sizes</h3>
<p>Here are the results from JOIN operation executed on CPU and GPU. We executed JOIN on the GPU with CUDA, on the GPU using CUDA kernels, and on the CPU using a single thread. We display the speed for the queries on different sizes of tables.<br />
<h4>All Results (y-axis: size of two relations eg. 2^23 tuples join 2^10 tuples, x-aixs: execution time(ms) ):</h4><br />
<img src="images/join_all.png" />
<br /><br />
<h4>GPU with CUDA plus data transfer: (y-axis: execution time(ms), x-axis: number of tuples of two relations)</h4>
<br />
<img src="images/join_gpu.png" />
<br /><br />
<h4>GPU with CUDA Kernels: (y-axis: execution time(ms), x-axis: number of tuples of two relations)</h4>
<br />
<img src="images/join_cuda_kernel.png" />
<br /><br />
<h4>CPU with Single Thread: (y-axis: execution time(ms), x-axis: number of tuples of two relations)</h4>
<br />
<img src="images/join_cpu.png" />
</p>
<br />

<h3>Analysis</h3>
<br />
<h3>GPU or CPU?</h3>
</div>

<div class="section" id="references">
<br /><br /><br /><br />
	<h2>References & Division of Work - MIRA & YINGCHAO</h2>

<p>
	<ul>
		<li>"Efficient Relational Algebra Algorithms and Data Structures for GPU"</li>
		<li>"Parallel Search On Video Cards"</li>
		<li><a href="http://db.grussell.org/index.html">Database eLearning Website</a></li>
	</ul>
</p>


	<h2>Division of Work</h2>
	<h3>Yingchao Liu</h3>
	<h4>Research</h4>
	<ul>
		<li>Found several research papers regarding database operations on GPU</li>
		<li>Researched the use and benefit of MemSQL</li>
		<li>Researched algorithms for SELECT and JOIN</li>
		<li>Researched the use of streams and other possible optimizations</li>
	</ul>
	<h4>Implementation</h4>
	<ul>
		<li>initial CUDA program of SELECT</li>
		<li>SELECT optimization using streams</li>
		<li>SELECT optimization using CUDA kernels</li>
		<li>SELECT optimization using SIMD</li>
		<li>initial sequential program of SELECT</li>
		<li>initial CUDA program of JOIN</li>
	</ul>
	<h4>Write-Up & Analysis</h4>
	<ul>
		<li>Gathered data on speedups for each implementation</li>
	</ul>
	<br />

	<h3>Mitra Raman</h3>
	<h4>Research</h4>
	<ul>
		<li>Read papers regarding database operations on GPU and CPU</li>
		<li>Researched and downloaded MemSQL to test the possible usage</li>
		<li>Researched implementations of SELECT and JOIN algorithms</li>
		<li>Researched possible optimizations for sequential versions using OpenMP</li>
	</ul>
	<h4>Implementation</h4>
	<ul>
		<li>SELECT optimization using OpenMP</li>
		<li>initial sequential program of JOIN</li>
	</ul>
	<h4>Write-Up & Analysis</h4>
	<ul>
		<li>Created graphs for each implementation, showing speedup vs. table size</li>
		<li>Compared speedup and performance of implementations for SELECT and JOIN</li>
		<li>Performed analysis on CPU vs GPU for SELECT and JOIN</li>
		<li>Created and designed final project webpage (this one!)</li>
		<li>Updated project schedule</li>
	</ul>
</div>

<footer>
<div class="footer-content">
	<p class="footer-text">Yingchao Liu (yingchal) & Mitra Raman (mitrar)</p>
        <ul class="footer-menu">
            <li><a href="index.html">Main Project Page</a></li>
            <li><a href="proposal.html">Project Proposal</a></li>
            <li><a href="checkpoint.html">Project Checkpoint</a></li>
        </ul>
    </div>
</footer>

</div>

</div>

<script type="text/javascript" src="js/jquery.pagescroller.js"></script>

<script>
  $('#wrapper').pageScroller({
    sectionClass: 'section',
    navigation: '#myNavigation',
  });

</script>

</body>
</html>
